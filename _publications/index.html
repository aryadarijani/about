---
layout: single
title: Publications
excerpt: "Publications"
share: false
collection: publications
---

<h2 id="peer-reviewed-conferences-and-journals-">Peer-reviewed conferences and journals:</h2>
<ul>
<li><strong>Deep Polynomial Neural Networks.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Stylianos Moschoglou, Giorgos Bouritsas, Jiankang Deng, Yannis Panagakis, Stefanos Zafeiriou<br>
      IEEE Transactions on Pattern Analysis and Machine Intelligence (<em>T-PAMI</em>), 2021. (impact factor 2019: 17.861) <br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://ieeexplore.ieee.org/document/9353253">Paper</a>; <a href="https://arxiv.org/abs/2006.13026">Paper (open access)</a>. &nbsp;<i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp; <a href="https://github.com/grigorisg9gr/polynomial_nets">Code</a>. <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We propose a new class of architectures that use polynomial expansions to approximate the target functions. We validate the proposed polynomial expansions (i.e. &Pi;-nets) in diverse experiments: data generation, data classifcation, face recognition and non-euclidean representation learning. </span></p>
    </div>

<li><strong>Non-adversarial polynomial synthesis.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Yannis Panagakis<br>
      Pattern Recognition Letters, 2020. <br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://www.sciencedirect.com/science/article/abs/pii/S0167865520304116">Paper</a>. <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We propose a decoder-only geenrator that uses a polynomial expansion to synthesize new images.</span></p>
    </div>

<li><strong>Reconstructing the Noise Manifold for Image Denoising.</strong>
    <div style="padding-left: 16px">
      <p>Ioannis Marras, <strong>Grigorios Chrysos</strong>, Ioannis Alexiou, Gregory Slabaugh, Stefanos Zafeiriou<br>
      European Conference on Computer Vision (<em>ECCV</em>), 2020. <br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123540596.pdf">PDF</a>. <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We propose learning the noise variance manifold along with typical image-to-image translation to obtain improved denoising.</span></p>
    </div>


<li><strong>Multilinear Latent Conditioning for Generating Unseen Attribute Combinations.</strong>
    <div style="padding-left: 16px">
      <p>Markos Georgopoulos, <strong>Grigorios Chrysos</strong>, Maja Pantic, Yannis Panagakis<br>
      International Conference on Machine Learning (<em>ICML</em>), 2020. <br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="http://proceedings.mlr.press/v119/georgopoulos20a/georgopoulos20a.pdf">PDF</a>. <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We extend conditional VAE to capture multiplicative interactions of the (annotated) attributes in the latent space. This enables generating images with unseen attribute combinations during training.</span></p>
    </div>

<li><strong>RoCGAN: Robust Conditional GAN.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Jean Kossaifi, Stefanos Zafeiriou<br>
      International Journal of Computer Vision (<em>IJCV</em>), 2020. (impact factor 2019: 11.042) <br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://link.springer.com/article/10.1007/s11263-020-01348-5">Paper (open access)</a>. &nbsp;<i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;<a href="https://github.com/grigorisg9gr/rocgan">Code</a>. <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We leverage structure in the output domain of a conditional data generation task (e.g., super-resolution) to improve the synthesized image. We experimentally validate that this results in synthesized images more robust to noise. Extension of the conference paper.</span></p>
    </div>

<li><strong>&Pi;-nets: Deep Polynomial Neural Networks.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Stylianos Moschoglou, Giorgos Bouritsas, Yannis Panagakis, Jiankang Deng, Stefanos Zafeiriou<br>
      Computer Vision and Pattern Recognition Conference (<em>CVPR</em>), 2020. <br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Chrysos_P-nets_Deep_Polynomial_Neural_Networks_CVPR_2020_paper.pdf">PDF</a>. &nbsp;<i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;<a href="https://github.com/grigorisg9gr/polynomial_nets">Code</a>. <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We use a high-order polynomial expansion as a function approximation method. The unknown parameters of the polynomial (i.e., high-order tensors) are estimated using a collective tensor factorization.</span></p>
    </div>


<li><strong>Motion Deblurring of Faces.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Paolo Favaro, Stefanos Zafeiriou<br>
      International Journal of Computer Vision (<em>IJCV</em>), 2019. (impact factor 2019: 11.042) <br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://link.springer.com/article/10.1007/s11263-018-1138-7">Paper (open access)</a>. <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We introduce a framework for tackling motion blur of faces. Our method simulates motion blur using averaging of video frames, while we collect a dataset that contains millions of such frames.</span></p>
    </div>

<li><strong>The Menpo Benchmark for Multi-pose 2D and 3D Facial Landmark Localisation and Tracking.</strong>
    <div style="padding-left: 16px">
      <p>Jiankang Deng, Anastasios Roussos, <strong>Grigorios Chrysos</strong>, Evangelos Ververas, Irene Kotsia, Jie Shen, Stefanos Zafeiriou<br>
      International Journal of Computer Vision (<em>IJCV</em>), 2019. (impact factor 2019: 11.042) <br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://link.springer.com/article/10.1007/s11263-018-1134-y">Paper (open access)</a>. <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">A semi-automatic framework is proposed for annotating challenging deformable images and videos.</span></p>
    </div>

<li><strong>Robust Conditional Generative Adversarial Networks.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Jean Kossaifi, Stefanos Zafeiriou<br>
      International Conference on Learning Representations (<em>ICLR</em>), 2019.<br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://arxiv.org/pdf/1805.08657.pdf">PDF</a>. &nbsp;<i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;<a href="https://github.com/grigorisg9gr/rocgan">Code</a>.<br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">The topic of conditional data generation task (e.g., super-resolution) is the focus of this work. We introduce a new pathway in the encoder-decoder generator to improve the synthesized image.</span></p>
    </div>


<li><strong>A Comprehensive Performance Evaluation of Deformable Face Tracking ''In-the-Wild''.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Epameinondas Antonakos, Patrick Snape, A. Asthana, Stefanos Zafeiriou<br>
      International Journal of Computer Vision (<em>IJCV</em>), 2018. (impact factor 2019: 11.042)<br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://link.springer.com/article/10.1007/s11263-017-0999-5">Paper (open access)</a>. &nbsp;<i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;<a href="https://github.com/grigorisg9gr/robust_deformable_face_tracking">Code</a>.<br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We conduct a large-scale study of deformable face tracking `in-the-wild', i.e., with videos captured in unrestricted conditions.</span></p>
    </div>


<li><strong>IPST: Incremental Pictorial Structures for model-free Tracking of deformable objects..</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Stefanos Zafeiriou, Epameinondas Antonakos<br>
      IEEE Transactions on Image Processing (<em>TIP</em>), 2018. (impact factor 2019: 9.34)<br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://ieeexplore.ieee.org/document/8316962">Paper</a>.<br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We introduce incremental pictorial structures for tracking deformable (part-based) objects, e.g., human body parts or fiducial points in the face.</span></p>
    </div>


<li><strong>PD2T: Person-specific Detection, Deformable Tracking.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Stefanos Zafeiriou<br>
      IEEE Transactions on Pattern Analysis and Machine Intelligence (<em>T-PAMI</em>), 2017. (impact factor 2019: 17.861)<br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://ieeexplore.ieee.org/abstract/document/8094942">Paper</a>.<br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We propose a framework for extracting object-specific statistics for tracking a (deformable) object.</span></p>
    </div>


<li><strong>Surface Based Object Detection in RGBD Images.</strong>
    <div style="padding-left: 16px">
      <p>Siddhartha Chandra<em>, <strong>Grigorios Chrysos</strong></em>, Iasonas Kokkinos<br>
      British Machine Vision Conference (<em>BMVC</em>), 2015.<br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://hal.inria.fr/hal-01263930/document">PDF</a>. Oral, acceptance rate: 7%.<br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We extend standard object detection pipelines by leveraging depth information and introducing viewpoint based mixture components.</span></p>
    </div>

</ul>







<h2 id="workshop-papers-">Workshop papers:</h2>
<ul>

<li><strong>Unsupervised Controllable Generation with Self-Training.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Jean Kossaifi, Zhiding Yu, Anima Anandkumar<br>
      International Conference on Machine Learning Workshops (ICMLW), 2020.<br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://arxiv.org/pdf/2007.09250.pdf">PDF</a>.<br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We modify the GAN architecture to achieve interpretable generation without using any supervision.</span></p>
    </div>



<li><strong>The 3D Menpo Facial Landmark Tracking Challenge.</strong>
    <div style="padding-left: 16px">
      <p>Stefanos Zafeiriou*<em>, <strong>Grigorios Chrysos</strong>*</em>, Anastasios Roussos*, Evangelos Ververas, J. Deng, George Trigeorgis<br>
      International Conference on Computer Vision Workshops (ICCVW), 2017.<br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w36/Zafeiriou_The_3D_Menpo_ICCV_2017_paper.pdf">PDF</a>.<br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">The first large-scale dataset with 3D annotations of facial landmarkrs is introduced.</span></p>
    </div>


<li><strong>Deep Face Deblurring.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Stefanos Zafeiriou<br>
      Computer Vision and Pattern Recognition Conference Workshops (CVPRW), 2017.<br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://openaccess.thecvf.com/content_cvpr_2017_workshops/w33/papers/Chrysos_Deep_Face_Deblurring_CVPR_2017_paper.pdf">PDF</a>.<br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">A method for face deblurring is proposed. The method utilizes weak supervision to guide the learning of the deep neural network.</span></p>
    </div>

<li><strong>The Menpo Facial Landmark Localisation Challenge.</strong>
    <div style="padding-left: 16px">
      <p>Stefanos Zafeiriou, George Trigeorgis, <strong>Grigorios Chrysos</strong>, J. Deng, Jie Shen<br>
      Computer Vision and Pattern Recognition Conference Workshops (CVPRW), 2017.<br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://openaccess.thecvf.com/content_cvpr_2017_workshops/w33/papers/Zafeiriou_The_Menpo_Facial_CVPR_2017_paper.pdf">PDF</a>.<br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">The first large-scale dataset with annotations of facial landmarkrs in both (semi-)frontal and profile poses is introduced.</span></p>
    </div>


<li><strong>The First Facial Landmark Tracking in-the-Wild Challenge: Benchmark and Results.</strong>
    <div style="padding-left: 16px">
      <p>Jie Shen, Stefanos Zafeiriou, <strong>Grigorios Chrysos</strong>, Jean Kossaifi, Georgios Tzimiropoulos, Maja Pantic<br>
      International Conference on Computer Vision Workshops (ICCVW), 2015.<br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://openaccess.thecvf.com/content_iccv_2015_workshops/w25/papers/Shen_The_First_Facial_ICCV_2015_paper.pdf">PDF</a>.<br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">The first large-scale dataset for facial landmark tracking is introduced.</span></p>
    </div>


<li><strong>Offline Deformable Face Tracking in Arbitrary Videos.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Epameinondas Antonakos, Stefanos Zafeiriou, Patrick Snape<br>
      International Conference on Computer Vision Workshops (ICCVW), 2015.<br>
      <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://openaccess.thecvf.com/content_iccv_2015_workshops/w25/papers/Chrysos_Offline_Deformable_Face_ICCV_2015_paper.pdf">PDF</a>.<br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We propose a framework that can extract object-specific statistics and can be used for tracking long sequences of videos.</span></p>
    </div>

</ul>

