---
layout: single
title: Publications
excerpt: "Publications"
share: false
collection: publications
---

<h2 id="peer-reviewed-conferences-and-journals-">Peer-reviewed conferences and journals:</h2>
<ul>
<li><strong>Grigorios Chrysos</strong>, Stylianos Moschoglou, Giorgos Bouritsas, Jiankang Deng, Yannis Panagakis, Stefanos Zafeiriou, Deep Polynomial Neural Networks. IEEE Transactions on Pattern Analysis and Machine Intelligence (<em>T-PAMI</em>), 2021. (impact factor 2019: 17.861)
    <ul>
    <li><i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://ieeexplore.ieee.org/document/9353253">Paper</a>; <a href="https://arxiv.org/abs/2006.13026">Paper (open access)</a>. &nbsp;<i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;<a href="https://github.com/grigorisg9gr/polynomial_nets">Code</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">We propose a new class of architectures that use polynomial expansions to approximate the target functions. We validate the proposed polynomial expansions (i.e. &Pi;-nets) in diverse experiments: data generation, data classifcation, face recognition and non-euclidean representation learning. </span></li>
    </ul>
</li>
<li><strong>Grigorios Chrysos</strong>, Yannis Panagakis: Non-adversarial polynomial synthesis. Pattern Recognition Letters, 2020.
    <ul>
    <li><i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://www.sciencedirect.com/science/article/abs/pii/S0167865520304116">Paper</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">We propose a decoder-only geenrator that uses a polynomial expansion to synthesize new images. </span></li>
    </ul>
</li>
<li>Ioannis Marras, <strong>Grigorios Chrysos</strong>, Ioannis Alexiou, Gregory Slabaugh, Stefanos Zafeiriou: Reconstructing the Noise Manifold for Image Denoising. European Conference on Computer Vision (<em>ECCV</em>), 2020.
    <ul>
    <li><i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123540596.pdf">PDF</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">We learn the noise variance manifold along with typical image-to-image translation to obtain improved denoising. </span></li>
    </ul>
</li>
<li>Markos Georgopoulos, <strong>Grigorios Chrysos</strong>, Yannis Panagakis, Maja Pantic: Multilinear Latent Conditioning for Generating Unseen Attribute Combinations. International Conference on Machine Learning (<em>ICML</em>), 2020.
    <ul>
    <li><i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="http://proceedings.mlr.press/v119/georgopoulos20a/georgopoulos20a.pdf">PDF</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">We extend conditional VAE to capture multiplicative interactions of the (annotated) attributes in the latent space. This enables generating images with unseen attribute combinations during training. </span></li>
    </ul>
</li>
<li><strong>Grigorios Chrysos</strong>, Jean Kossaifi, Stefanos Zafeiriou: RoCGAN: Robust Conditional GAN. International Journal of Computer Vision (<em>IJCV</em>), 2020. (impact factor 2019: 11.042)
    <ul>
    <li><i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://link.springer.com/article/10.1007/s11263-020-01348-5">Paper (open access)</a>. &nbsp;<i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;<a href="https://github.com/grigorisg9gr/rocgan">Code</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">We leverage structure in the output domain of a conditional data generation task (e.g., super-resolution) to improve the synthesized image. We experimentally validate that this results in synthesized images more robust to noise. Extension of the conference paper. </span></li>
    </ul>
</li>
<li><strong>Grigorios Chrysos</strong>, Stylianos Moschoglou, Giorgos Bouritsas, Yannis Panagakis, Jiankang Deng, Stefanos Zafeiriou, &Pi;-nets: Deep Polynomial Neural Networks. Computer Vision and Pattern Recognition Conference (<em>CVPR</em>), 2020.
    <ul>
    <li><i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Chrysos_P-nets_Deep_Polynomial_Neural_Networks_CVPR_2020_paper.pdf">PDF</a>. &nbsp;<i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;<a href="https://github.com/grigorisg9gr/polynomial_nets">Code</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">We use a high-order polynomial expansion as a function approximation method. The unknown parameters of the polynomial (i.e., high-order tensors) are estimated using a collective tensor factorization. </span></li>
    </ul>
</li>
<li><strong>Grigorios Chrysos</strong>, Paolo Favaro, Stefanos Zafeiriou: Motion Deblurring of Faces. International Journal of Computer Vision (<em>IJCV</em>), 2019. (impact factor 2019: 11.042)
    <ul>
    <li><i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://link.springer.com/article/10.1007/s11263-018-1138-7">Paper (open access)</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">We introduce a framework for tackling motion blur of faces. Our method simulates motion blur using averaging of video frames, while we collect a dataset that contains millions of such frames. </span></li>
    </ul>
</li>
<li>Jiankang Deng, Anastasios Roussos, <strong>Grigorios Chrysos</strong>, Evangelos Ververas, Irene Kotsia, Jie Shen, Stefanos Zafeiriou: The Menpo Benchmark for Multi-pose 2D and 3D Facial Landmark Localisation and Tracking. International Journal of Computer Vision (<em>IJCV</em>), 2019. (impact factor 2019: 11.042)
    <ul>
    <li><i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://link.springer.com/article/10.1007/s11263-018-1134-y">Paper (open access)</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">A semi-automatic framework is proposed for annotating challenging deformable images and videos.</span></li>
    </ul>
</li>
<li><strong>Grigorios Chrysos</strong>, Jean Kossaifi, Stefanos Zafeiriou: Robust Conditional Generative Adversarial Networks. International Conference on Learning Representations (<em>ICLR</em>), 2019.
    <ul>
    <li><i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://arxiv.org/pdf/1805.08657.pdf">PDF</a>. <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;<a href="https://github.com/grigorisg9gr/rocgan">Code</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">The topic of conditional data generation task (e.g., super-resolution) is the focus of this work. We introduce a new pathway in the encoder-decoder generator to improve the synthesized image.</span></li>
    </ul>
</li>
<li><strong>Grigorios Chrysos</strong>, Epameinondas Antonakos, Patrick Snape, A. Asthana, Stefanos Zafeiriou: A Comprehensive Performance Evaluation of Deformable Face Tracking ''In-the-Wild''. International Journal of Computer Vision (<em>IJCV</em>), 2018. (impact factor 2019: 11.042)
    <ul>
    <li><i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://link.springer.com/article/10.1007/s11263-017-0999-5">Paper (open access)</a>. &nbsp;<i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;<a href="https://github.com/grigorisg9gr/robust_deformable_face_tracking">Code</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">We conduct a large-scale study of deformable face tracking `in-the-wild', i.e., with videos captured in unrestricted conditions. </span></li>
    </ul>
</li>
<li><strong>Grigorios Chrysos</strong>, Stefanos Zafeiriou, Epameinondas Antonakos: IPST: Incremental Pictorial Structures for model-free Tracking of deformable objects. IEEE Transactions on Image Processing (<em>TIP</em>), 2018. (impact factor 2019: 9.34)
    <ul>
    <li><i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://ieeexplore.ieee.org/document/8316962">Paper</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">We introduce incremental pictorial structures for tracking deformable (part-based) objects, e.g., human body parts or fiducial points in the face.</span></li>
    </ul>
</li>
<li><strong>Grigorios Chrysos</strong>, Stefanos Zafeiriou: PD2T: Person-specific Detection, Deformable Tracking. IEEE Transactions on Pattern Analysis and Machine Intelligence (<em>T-PAMI</em>), 2017. (impact factor 2019: 17.861)
    <ul>
    <li><i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://ieeexplore.ieee.org/abstract/document/8094942">Paper</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;"> We propose a framework for extracting object-specific statistics for tracking a (deformable) object.</span></li>
    </ul>
</li>
<li>Siddhartha Chandra<em>, <strong>Grigorios Chrysos</strong></em>, Iasonas Kokkinos: Surface Based Object Detection in RGBD Images. British Machine Vision Conference (<em>BMVC</em>), 2015. 
    <ul>
    <li><i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;<a href="https://hal.inria.fr/hal-01263930/document">PDF</a>. Oral, acceptance rate: 7%.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">We extend standard object detection pipelines by leveraging depth information and introducing viewpoint based mixture components.</span></li>
    </ul>
</li>
</ul>


<h2 id="workshop-papers-">Workshop papers:</h2>
<ul>
<li><strong>Grigorios Chrysos</strong>, Jean Kossaifi, Zhiding Yu, Anima Anandkumar: Unsupervised Controllable Generation with Self-Training, International Conference on Machine Learning Workshops (ICMLW), 2020.
    <ul>
    <li><a href="https://arxiv.org/pdf/2007.09250.pdf">PDF</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">We modify the GAN architecture to achieve interpretable generation without using any supervision. </span></li>
    </ul>
</li>
<li>Stefanos Zafeiriou*<em>, <strong>Grigorios Chrysos</strong>*</em>, Anastasios Roussos*, Evangelos Ververas, J. Deng, George Trigeorgis: The 3D Menpo Facial Landmark Tracking Challenge. International Conference on Computer Vision Workshops (ICCVW), 2017.
    <ul>
    <li><a href="https://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w36/Zafeiriou_The_3D_Menpo_ICCV_2017_paper.pdf">PDF</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">The first large-scale dataset with 3D annotations of facial landmarkrs is introduced.</span></li>
    </ul>
</li>
<li><strong>Grigorios Chrysos</strong>, Stefanos Zafeiriou: Deep Face Deblurring. Computer Vision and Pattern Recognition Conference Workshops (CVPRW), 2017.
    <ul>
    <li><a href="https://openaccess.thecvf.com/content_cvpr_2017_workshops/w33/papers/Chrysos_Deep_Face_Deblurring_CVPR_2017_paper.pdf">PDF</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">A method for face deblurring is proposed. The method utilizes weak supervision to guide the learning of the deep neural network. </span></li>
    </ul>
</li>
<li>Stefanos Zafeiriou, George Trigeorgis, <strong>Grigorios Chrysos</strong>, J. Deng, Jie Shen: The Menpo Facial Landmark Localisation Challenge. Computer Vision and Pattern Recognition Conference Workshops (CVPRW), 2017.
    <ul>
    <li><a href="https://openaccess.thecvf.com/content_cvpr_2017_workshops/w33/papers/Zafeiriou_The_Menpo_Facial_CVPR_2017_paper.pdf">PDF</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">The first large-scale dataset with annotations of facial landmarkrs in both (semi-)frontal and profile poses is introduced.</span></li>
    </ul>
</li>
<li>Jie Shen, Stefanos Zafeiriou, <strong>Grigorios Chrysos</strong>, Jean Kossaifi, Georgios Tzimiropoulos, Maja Pantic: The First Facial Landmark Tracking in-the-Wild Challenge: Benchmark and Results. International Conference on Computer Vision Workshops (ICCVW), 2015.
    <ul>
    <li><a href="https://openaccess.thecvf.com/content_iccv_2015_workshops/w25/papers/Shen_The_First_Facial_ICCV_2015_paper.pdf">PDF</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">The first large-scale dataset for facial landmark tracking is introduced.</span></li>
    </ul>
</li>
<li><strong>Grigorios Chrysos</strong>, Epameinondas Antonakos, Stefanos Zafeiriou, Patrick Snape: Offline Deformable Face Tracking in Arbitrary Videos. International Conference on Computer Vision Workshops (ICCVW), 2015.
    <ul>
    <li><a href="https://openaccess.thecvf.com/content_iccv_2015_workshops/w25/papers/Chrysos_Offline_Deformable_Face_ICCV_2015_paper.pdf">PDF</a>.</li>
    <li style="line-height: 13px;"><span style="color: #609999; font-size: 12px;">We propose a framework that can extract object-specific statistics and can be used for tracking long sequences of videos.</span></li>
    </ul>
</li>
</ul>

