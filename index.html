---
layout: single
title: About me
author_profile: true
tags: [About me, machine learning]
comments: false
---


<p>I am an Assistant Professor in University of Wisconsin-Madison. </p>

My research focuses on reliable machine learning and the design and study of expressive models that are robust to noise and generalize well in out-of-distribution data. Concretely,

<ul>
    <li>I have worked extensively on polynomial networks (PNs) that capture high-degree interactions between inputs. My short-term goals are to understand the inductive bias and properties of existing architectures through empirical and theoretical studies. I am interested in the complete theoretical understanding of (neural/polynomial) networks, including their expressivity, trainability, generalization properties, and inductive biases. My recent work has provided the first characterization of the generalization of this class of functions, and I have focused on the spectral bias of high-degree polynomials, highlighting how PNs can learn higher frequency functions faster than regular feed-forward networks.</li>

    <li>My goal is to understand the extrapolation properties of existing networks and make improvements to their performance, especially in the context of conditional generative models. In the short-term, I will continue to explore the robustness of these models to malicious attacks, as well as the impact of adversarial perturbations on different classes. In the long-term, I plan to design models that are both robust and fair, and can generalize well to unseen attribute combinations. </li>
</ul>

<h2>News</h2>
<ul>
    <li>January 2024: The following papers are accepted at <strong>ICLR 2024</strong>:
        <ul>
                <li>'<span style="color: #0000ff;"><a href="https://arxiv.org/abs/2403.09889">Generalization of Scaled Deep ResNets in the Mean-Field Regime</a></span>' (as spotlight),</li>
                <li>'<span style="color: #0000ff;"><a href="https://arxiv.org/abs/2401.17992">Multilinear Operator Networks</a></span>',</li>
                <li>'<span style="color: #0000ff;"><a href="https://arxiv.org/abs/2401.11618">Efficient local linearity regularization to overcome catastrophic overfitting</a></span>',</li>
                <li>'<span style="color: #0000ff;"><a href="#">Robust NAS under adversarial training: benchmark, theory, and beyond</a></span>'.</li>
        </ul></li>
    <li>January 2024: The following paper has been accepted at <strong>Transactions on Machine Learning Research (TMLR)</strong>: '<em><a href="https://openreview.net/forum?id=oCBsxCov2g"><span style="color: #0000ff;">PNeRV: A Polynomial Neural Representation for Videos</span></a></em>'. </li>
    <li>November 2023: I was recognized as a <a href="https://neurips.cc/Conferences/2023/ProgramCommittee"><strong>top reviewer</strong></a> at <strong>NeurIPS 2023</strong>.</li>
    <li>October 2023: The following papers are accepted at <strong>NeurIPS 2023</strong>: <a href="https://arxiv.org/abs/2310.18672"><span style="color: #0000ff;">`Maximum Independent Set: Self-Training through Dynamic Programming'</span></a> and <a href="https://arxiv.org/abs/2311.01575"><span>`On the Convergence of Encoder-Only Shallow Transformers'</span></a>.
    <li>June 2023: The slides and the recording of our tutorial titled `Deep Learning Theory for Vision' at CVPR'23 are available: <a href="https://dl-theory.github.io/assets/CVPR.pdf">Slides</a> and <a href="https://www.youtube.com/watch?v=XtPGP9SXyiI">recording</a>. More information: <a href="https://dl-theory.github.io/">https://dl-theory.github.io/</a>. 
    <li>May 2023: The following paper has been accepted at <strong>Transactions on Machine Learning Research (TMLR)</strong>: <a href="https://openreview.net/forum?id=N7lCDaeNiS"><span style="color: #0000ff;">`Federated Learning under Covariate Shifts with Generalization Guarantees'</span></a>.
    <li>April 2023: The following paper has been accepted at <strong>ICML 2023</strong>: <a href="https://arxiv.org/abs/2305.19377"><span style="color: #0000ff;">`Benign Overfitting in Deep Neural Networks under Lazy Training'</span></a>.
    <li>April 2023: Awarded the <a href="https://www.daad.de/en/the-daad/postdocnet/details-and-application/">DAAD AInet Fellowship</a>, which is awarded to outstanding early career researchers. Topic: generative model in ML.</li>
    <li>March 2023: The following paper has been accepted at <strong>CVPR 2023</strong>: '<em><a href="http://arxiv.org/abs/2303.13896"><span style="color: #0000ff;">Regularization of polynomial networks for image recognition</span></a></em>'. </li>
    <li>February 2023: Organizer of the tutorial on 'Polynomial Nets' in conjunction with AAAI'23: <a href="https://polynomial-nets.github.io/">https://polynomial-nets.github.io/</a>.
    <li>January 2023: The following paper has been accepted at <strong>Transactions on Machine Learning Research (TMLR)</strong>: '<em><a href="https://openreview.net/forum?id=wkecshlYxI"><span style="color: #0000ff;">Revisiting adversarial training for the worst-performing class</span></a></em>'. </li>
    <li>December 2022: The following paper has been accepted at <strong>Transactions on Pattern Analysis and Machine Intelligence</strong>: '<em><a href="https://ieeexplore.ieee.org/abstract/document/10076897"><span style="color: #0000ff;">Linear Complexity Self-Attention with 3rd Order Polynomials</span></a></em>'. </li>
    <li>October 2022: I was recognized as a <a href="https://neurips.cc/Conferences/2022/ProgramCommittee"><strong>best reviewer</strong></a> at <strong>NeurIPS 2022</strong>.</li>
    <li>September 2022: The following papers have been accepted at <strong>NeurIPS 2022</strong>: 
        <ul>
                <li>'<span style="color: #0000ff;"><a href="https://openreview.net/pdf?id=m8vzptcFKsT">Robustness in deep learning: The good (width), the bad (depth), and the ugly (initialization)</a></span>',</li>
                <li>'<span style="color: #0000ff;"><a href="https://openreview.net/pdf?id=aQySSrCbBul">Generalization Properties of NAS under Activation and Skip Connection Search</a></span>',</li>
                <li>'<span style="color: #0000ff;"><a href="https://openreview.net/pdf?id=gsdHDI-p6NI">Sound and Complete Verification of Polynomial Networks</a></span>',&nbsp;</li>
                <li>'<span style="color: #0000ff;"><a href="https://openreview.net/pdf?id=_cXUMAnWJJj">Extrapolation and Spectral Bias of Neural Nets with Hadamard Product: a Polynomial Net Study</a></span>'.</li>
        </ul></li>
    <li>August 2022: <a href="https://www.slideshare.net/GrigorisChrysos/tutorial-on-polynomial-networks-at-cvpr22">The slides</a> used in the tutorial on polynomial networks (organized at CVPR'22) have been released. </li>
    <li>July 2022: I was awarded a <a href="https://icml.cc/Conferences/2022/Reviewers"><strong>best reviewer award (top 10%)</strong></a> at <strong>ICML 2022</strong>.</li>
    <li>July 2022: The following papers have been accepted at <strong>ECCV 2022</strong>: '<span style="color: #0000ff;"><a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136850682.pdf">Augmenting Deep Classifiers with Polynomial Neural Networks</a></span>' and '<span style="color: #0000ff;"><a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136680457.pdf">MimicME: A Large Scale Diverse 4D Database for Facial Expression Analysis</a></span>'. More information soon.</li>
    <li>June 2022: Organizer of the tutorial on 'Polynomial Nets' in conjunction with CVPR'22: <a href="https://polynomial-nets.github.io/">https://polynomial-nets.github.io/previous_versions/index.html</a>.
    <li>April 2022: I was awarded a <a href="https://iclr.cc/Conferences/2022/Reviewers"><strong>highlighted reviewer award</strong></a> at <strong>ICLR 2022</strong>.</li>
    <li>March 2022: The following paper has been accepted at <strong>CVPR 2022</strong>: '<span style="color: #0000ff;"><em><a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Georgopoulos_Cluster-Guided_Image_Synthesis_With_Unconditional_Models_CVPR_2022_paper.pdf">Cluster-guided Image Synthesis with Unconditional Models</a></em></span>'.</li>
    <li>February 2022: <a href="https://www.youtube.com/watch?v=l1xievUFdAw"><strong>My talk</strong></a> on polynomial networks at the  UCL Centre for Artificial Intelligence has been uploaded online.</li>
    <li>January 2022: The following papers have been accepted at <strong>ICLR 2022</strong>: '<span style="color: #0000ff;"><em><a href="https://openreview.net/pdf?id=dQ7Cy_ndl1s">Controlling the Complexity and Lipschitz Constant improves Polynomial Nets</a></em></span>' and '<span style="color: #0000ff;"><em><a href="https://openreview.net/pdf?id=P7FLfMLTSEX">The Spectral Bias of Polynomial Neural Networks</a></em></span>'.</li>
    <li>October 2021: The following paper has been accepted at <strong>NeurIPS 2021</strong>: '<a href="https://proceedings.neurips.cc/paper/2021/file/ef0d3930a7b6c95bd2b32ed45989c61f-Paper.pdf"><span style="color: #0000ff;">Conditional Generation Using Polynomial Expansions</span></a>'.</li>
    <li>July 2021: I was awarded a <a href="https://icml.cc/Conferences/2021/Reviewers"><strong>best reviewer award (top 10%)</strong></a> at <strong>ICML 2021</strong>.</li>
    <li>The following paper has been accepted at <strong>Proceedings of the IEEE (2021)</strong>: '<em><a href="https://ieeexplore.ieee.org/document/9420085"><span style="color: #0000ff;">Tensor methods in computer vision and deep learning</span></a></em>'</li>
</ul>
